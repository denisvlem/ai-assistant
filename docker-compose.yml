version: '3.7'
services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
    entrypoint: >
      /bin/sh -c "
        ollama serve &
        sleep 2 &&
        ollama pull gemma3:4b-it-q4_K_M &&
        ollama pull mxbai-embed-large &&
        wait
      "
    restart: unless-stopped
  ai-assistant:
    depends_on:
      - ollama
    build: .
    ports:
      - "8080:8080"
    environment:
      SERVER_PORT: 8080